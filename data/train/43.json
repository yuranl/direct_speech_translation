{"wav_id": "43", "speaker": "43", "offset": "6.900", "duration": "0.680", "wav": "43.wav", "translation": "Hello, everyone!", "transcript": "大家好！"}
{"wav_id": "43", "speaker": "43", "offset": "7.700", "duration": "2.850", "wav": "43.wav", "translation": "My name is Ouyang Jian. I am a principal architect of Baidu.", "transcript": "我是来自于百度的主任架构师欧阳剑。"}
{"wav_id": "43", "speaker": "43", "offset": "10.910", "duration": "7.470", "wav": "43.wav", "translation": "Today, I will be introducing the architecture and application of Baidu's FPGA-based AI processor.", "transcript": "今天由我给大家带来百度自研AI FPGA版的架构及应用，我叫欧阳剑。"}
{"wav_id": "43", "speaker": "43", "offset": "18.870", "duration": "3.130", "wav": "43.wav", "translation": "Today's course consists of the following parts.", "transcript": "呃今天的呃课程会分为以下几部分。"}
{"wav_id": "43", "speaker": "43", "offset": "22.340", "duration": "2.480", "wav": "43.wav", "translation": "In the first part, I will explain what an FPGA is.", "transcript": "第一部分我会给大家讲一下什么是FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "25.300", "duration": "3.090", "wav": "43.wav", "translation": "In the second part, I will talk about the characteristics of AI computing.", "transcript": "第二部分我会给大家讲一下AI计算的特点。"}
{"wav_id": "43", "speaker": "43", "offset": "28.660", "duration": "5.990", "wav": "43.wav", "translation": "In the third part, I will explain why FPGAs are not just suitable but excellent for AI computing.", "transcript": "第三部分就会给大家带来为什么FPGA能做AI计算而且能做得非常的好。"}
{"wav_id": "43", "speaker": "43", "offset": "35.000", "duration": "7.760", "wav": "43.wav", "translation": "Next, I will share with you how Baidu has used FPGAs to develop its own AI accelerator in the past six years.", "transcript": "最后给大家分享一下百度在过去六年的时间里面，怎么用FPGA来做我们自己的AI的加速器。"}
{"wav_id": "43", "speaker": "43", "offset": "43.150", "duration": "1.990", "wav": "43.wav", "translation": "The final part is a summary.", "transcript": "最后给大家带来我们的总结。"}
{"wav_id": "43", "speaker": "43", "offset": "45.970", "duration": "3.070", "wav": "43.wav", "translation": "Let's begin by talking about what an FPGA is.", "transcript": "那我们就以我们就开始讲什么是FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "50.570", "duration": "7.500", "wav": "43.wav", "translation": "FPGA is short for field-programmable gate array.", "transcript": "啊FPGA它是Programmable Gate Array这样的一个缩写，就是现场可编程门阵列的意思。"}
{"wav_id": "43", "speaker": "43", "offset": "58.460", "duration": "3.310", "wav": "43.wav", "translation": "It is actually a chip which has a configurable circuit structure.", "transcript": "它其实是一块可以自己定义电路结构的一个芯片。"}
{"wav_id": "43", "speaker": "43", "offset": "62.190", "duration": "11.090", "wav": "43.wav", "translation": "You can think of it as a blank slate on which you can design specific circuit structures, implement your own adders, multipliers, logic gates, and so on via programming.", "transcript": "你可以认为里面电路是空白的，你自己可以定义里面的具体电路结构，实现自己的加法器、乘法器、逻辑门等等等等，都可以通过自己的编程来实现这些具体的电路。"}
{"wav_id": "43", "speaker": "43", "offset": "73.920", "duration": "2.480", "wav": "43.wav", "translation": "An FPGA has rich resources inside.", "transcript": "那一个FPGA里面实际上是有非常丰富的资源的。"}
{"wav_id": "43", "speaker": "43", "offset": "76.430", "duration": "1.190", "wav": "43.wav", "translation": "You can look at the picture on the right.", "transcript": "大家可以看右边这个图。"}
{"wav_id": "43", "speaker": "43", "offset": "78.100", "duration": "1.850", "wav": "43.wav", "translation": "Different colors represent different resources.", "transcript": "不同的颜色代表不同的资源。"}
{"wav_id": "43", "speaker": "43", "offset": "80.610", "duration": "3.310", "wav": "43.wav", "translation": "Pink represents lookup tables.", "transcript": "呃橙就是粉红色的，可以是认为是查找表。"}
{"wav_id": "43", "speaker": "43", "offset": "84.260", "duration": "9.540", "wav": "43.wav", "translation": "An FPGA can contain more than one million lookup tables, which are used to implement general logic functions such as logic operations, or some additions and multiplications.", "transcript": "它里面有很多很多查找表，可能有上百万个，查找表会用来实现一些通用的逻辑，例如说一些逻辑的计算，或者一些加法、乘法，它都可以实现。"}
{"wav_id": "43", "speaker": "43", "offset": "94.420", "duration": "10.330", "wav": "43.wav", "translation": "Orange represents registers, which are used to hold data to increase the working frequency.", "transcript": "那第二个就是呃大家看橙色的呃黄色的是那种呃寄存器，寄存器是用来缓存数据，然后用来提高这个工作频率的。"}
{"wav_id": "43", "speaker": "43", "offset": "105.980", "duration": "2.020", "wav": "43.wav", "translation": "An FPGA contains a lot of registers.", "transcript": "FPGA里面有大量的寄存器。"}
{"wav_id": "43", "speaker": "43", "offset": "108.730", "duration": "4.240", "wav": "43.wav", "translation": "Blue represents DSPs.", "transcript": "第三个就是蓝色的那些块，那些块可认为是DSP。"}
{"wav_id": "43", "speaker": "43", "offset": "113.410", "duration": "1.940", "wav": "43.wav", "translation": "DSPs are very important.", "transcript": "这个在现在DSP里面非常重要。"}
{"wav_id": "43", "speaker": "43", "offset": "115.760", "duration": "4.960", "wav": "43.wav", "translation": "They are a basic unit of complex mathematical calculations, including multiplication, addition, and accumulation.", "transcript": "它基本上就是复杂数学计算的一个基本的单元，实现了乘法、加法和累加。"}
{"wav_id": "43", "speaker": "43", "offset": "121.520", "duration": "1.700", "wav": "43.wav", "translation": "They are critical for AI computing.", "transcript": "这个就对AI计算非常关键。"}
{"wav_id": "43", "speaker": "43", "offset": "123.410", "duration": "4.150", "wav": "43.wav", "translation": "Green represents block RAMs, that is, on-chip SRAMs.", "transcript": "那呃绿色的部分是那个Block RAM，就是片内的SRAM。"}
{"wav_id": "43", "speaker": "43", "offset": "128.000", "duration": "2.030", "wav": "43.wav", "translation": "They are used for on-chip data buffering.", "transcript": "这个是用来做片内的数据缓存用的。"}
{"wav_id": "43", "speaker": "43", "offset": "130.350", "duration": "2.190", "wav": "43.wav", "translation": "They are also very important for AI computing.", "transcript": "这个也非常重要，对于AI计算。"}
{"wav_id": "43", "speaker": "43", "offset": "132.860", "duration": "6.040", "wav": "43.wav", "translation": "They are critical for data locality, high bandwidth, and low latency.", "transcript": "因为是要对数据的locality，对这个数据的高带宽、低延时非常关键。"}
{"wav_id": "43", "speaker": "43", "offset": "139.210", "duration": "2.110", "wav": "43.wav", "translation": "Therefore, we must make full use of the on-chip SRAMs.", "transcript": "所以我们是要充分用好片内的SRAM。"}
{"wav_id": "43", "speaker": "43", "offset": "141.920", "duration": "2.380", "wav": "43.wav", "translation": "I/O is very important for FPGAs.", "transcript": "那对FPGA来说还有非常重要就是I/O。"}
{"wav_id": "43", "speaker": "43", "offset": "144.800", "duration": "2.020", "wav": "43.wav", "translation": "The I/O resource is used for external communications.", "transcript": "I/O是用来对跟外界通信的。"}
{"wav_id": "43", "speaker": "43", "offset": "146.880", "duration": "6.030", "wav": "43.wav", "translation": "For example, we use PCIe I/O for communications with the CPU and DDR I/O for communications with the DDR memory.", "transcript": "例如说我们通过PCIE的I/O来跟CPU来通信，通过DDR的I/O来跟DDR内存的通信。"}
{"wav_id": "43", "speaker": "43", "offset": "154.360", "duration": "3.340", "wav": "43.wav", "translation": "For AI computing, an FPGA cannot complete all calculations alone.", "transcript": "对于AI计算来说，我们一个FPGA是不能完成所有计算的。"}
{"wav_id": "43", "speaker": "43", "offset": "157.730", "duration": "2.540", "wav": "43.wav", "translation": "Instead, it must work together with the CPU.", "transcript": "是要必须要跟C CPU协同工作在一起。"}
{"wav_id": "43", "speaker": "43", "offset": "160.630", "duration": "4.440", "wav": "43.wav", "translation": "Therefore, I/O is a very important bridge to interconnect with external computing units.", "transcript": "所以说这个I/O就是来连接外界计算单元的一个很重要的一个桥梁。"}
{"wav_id": "43", "speaker": "43", "offset": "165.750", "duration": "2.700", "wav": "43.wav", "translation": "For FPGAs, there is another important part.", "transcript": "那对于FPGA来说还有一个很重要的部分。"}
{"wav_id": "43", "speaker": "43", "offset": "168.870", "duration": "1.410", "wav": "43.wav", "translation": "Take a look at these red lines.", "transcript": "就是看红色的这线。"}
{"wav_id": "43", "speaker": "43", "offset": "170.760", "duration": "2.010", "wav": "43.wav", "translation": "They are interconnection wires inside the FPGAs.", "transcript": "它像是FPGA的内部的互联线。"}
{"wav_id": "43", "speaker": "43", "offset": "173.070", "duration": "6.980", "wav": "43.wav", "translation": "These wires interconnect all the resources I mentioned just now, enabling them to perform complex calculations.", "transcript": "它能把我刚才所讲的所有的这些资源给连起来，变成一个有机的一个整体，来实现一个非常复杂的计算。"}
{"wav_id": "43", "speaker": "43", "offset": "181.200", "duration": "7.580", "wav": "43.wav", "translation": "FPGA programming is different from CPU and GPU programming, which we are more familiar with.", "transcript": "呃FPGA的编程方式，可能跟大家所一般呃认为的C CPU的编程方式和GPU 编程方式不太一样。"}
{"wav_id": "43", "speaker": "43", "offset": "189.140", "duration": "8.240", "wav": "43.wav", "translation": "For microinstruction-driven architectures like the CPU and GPU, their programming language is C++, C, or Python.", "transcript": "对于这种对于微指令的架构，像CPU和GPU，它的编程实际是用C C++、C或者说是Python等等等等。"}
{"wav_id": "43", "speaker": "43", "offset": "197.710", "duration": "4.710", "wav": "43.wav", "translation": "These languages are converted to assembly languages using compilers before execution on the CPU or GPU.", "transcript": "这种语言通过编译器把它变成汇编，然后就是在CPU或GPU上运行。"}
{"wav_id": "43", "speaker": "43", "offset": "203.270", "duration": "6.990", "wav": "43.wav", "translation": "An FPGA is essentially a circuit and so a circuit description language is used for its programming.", "transcript": "但是对FPGA来说，它本质上它是一个电路，所以说它的编程是用电路描述语言来写的。"}
{"wav_id": "43", "speaker": "43", "offset": "210.560", "duration": "1.740", "wav": "43.wav", "translation": "We usually use Verilog.", "transcript": "呃我们一般是用Verilog比较多。"}
{"wav_id": "43", "speaker": "43", "offset": "213.180", "duration": "8.830", "wav": "43.wav", "translation": "Conversely, for CPUs, C is often used to program its logic, which is then converted into instructions using compilers.", "transcript": "然后它本质上跟CPU都不一样，CPU可能是用用C语言来描述这个逻辑，然后来让编译器来把它翻译成指令。"}
{"wav_id": "43", "speaker": "43", "offset": "222.980", "duration": "8.390", "wav": "43.wav", "translation": "But for a circuit, we are actually designing its structure by using a set of algorithms.", "transcript": "但是对于电路来说，我们实际上是在设计一个电路的结构，根据一套根据我们的算法应用把它转换成这个电路结构。"}
{"wav_id": "43", "speaker": "43", "offset": "232.240", "duration": "5.450", "wav": "43.wav", "translation": "At the same time, to develop FPGAs well, we need the tools provided by the FPGA manufacturer.", "transcript": "呃同时呢我们要做好FPGA开发，是是需要FPGA厂家提供这个工具的。"}
{"wav_id": "43", "speaker": "43", "offset": "237.770", "duration": "5.560", "wav": "43.wav", "translation": "For example, to convert Verilog into netlists, we need the synthesizer provided by the FPGA manufacturer.", "transcript": "例如说我们要把Verilog变成网表，我们是要FPGA厂家提供的这种综合器。"}
{"wav_id": "43", "speaker": "43", "offset": "243.930", "duration": "9.390", "wav": "43.wav", "translation": "To convert netlists into FPGA binary files, we need tools for placement routing, wiring, and generating binaries.", "transcript": "把网表变成真正的FPGA的二认证文件，我们是要这里面需要一个布局的工具布布线的工具，还有那个Binary生成的工具。"}
{"wav_id": "43", "speaker": "43", "offset": "253.770", "duration": "1.630", "wav": "43.wav", "translation": "These are all highly complex tools.", "transcript": "这些工具都非常的复杂。"}
{"wav_id": "43", "speaker": "43", "offset": "256.250", "duration": "5.190", "wav": "43.wav", "translation": "Because FPGAs are becoming bigger and bigger, more time is required for the whole development.", "transcript": "因为FPGA越来越大，所对整个开发的时间要求也非常的高。"}
{"wav_id": "43", "speaker": "43", "offset": "261.540", "duration": "5.370", "wav": "43.wav", "translation": "Generally, for a large FPGA, the time required for placement and routing is between ten to twenty hours.", "transcript": "一般是要如果一个大的FPGA，它的布局布线的时间可能需要十几二十个小时。"}
{"wav_id": "43", "speaker": "43", "offset": "268.550", "duration": "9.050", "wav": "43.wav", "translation": "In the picture in the lower left corner, we can see a small program for FPGAs developed using Verilog.", "transcript": "呃大家可以看，呃左下角那个图是其实是一个非一个比较典型的一个呃FPGA用Verilog开发的一个一段小程序。"}
{"wav_id": "43", "speaker": "43", "offset": "277.920", "duration": "6.080", "wav": "43.wav", "translation": "We can see that its structure is completely different from that of C  and the logic is also completely different.", "transcript": "大家看它跟C C语言的结构是完全不一样的，它的描述的逻辑也是完全不一样。"}
{"wav_id": "43", "speaker": "43", "offset": "284.260", "duration": "6.430", "wav": "43.wav", "translation": "Since it actually involves a circuit structure, it describes a specific operation in a parallel manner.", "transcript": "它实际上因为涉及电路结构，所以它是一种以一种并行的方式来描述一个具体的一个操作。"}
{"wav_id": "43", "speaker": "43", "offset": "291.380", "duration": "3.160", "wav": "43.wav", "translation": "After synthesis, a gate netlist is obtained.", "transcript": "那这样一个语言综合之后就会得得到一个门的网表。"}
{"wav_id": "43", "speaker": "43", "offset": "294.960", "duration": "2.670", "wav": "43.wav", "translation": "This netlist is irrelated to the FPGA structure.", "transcript": "这个网表是跟具体的FPGA结构是无关的。"}
{"wav_id": "43", "speaker": "43", "offset": "297.850", "duration": "1.580", "wav": "43.wav", "translation": "It is a gate structure.", "transcript": "它就是一个门的一个结构。"}
{"wav_id": "43", "speaker": "43", "offset": "299.860", "duration": "9.090", "wav": "43.wav", "translation": "After layout arrangement and wiring are completed by using the EDA tool, it can be mapped to specific elements in the FPGA, such as LUTs, registers, DSPs, and BRAMs.", "transcript": "那通过EDA工具布局布线之后，它就能对应到FPGA逻辑里面各个具体的单元，像LUT、寄存器、DSP、BRAM等等等等。"}
{"wav_id": "43", "speaker": "43", "offset": "309.690", "duration": "10.410", "wav": "43.wav", "translation": "Finally, these FPGA tools are used to choose the wires for interconnecting these logic resources to form a workable unit.", "transcript": "那最后呢就通过这些嘶FPGA工具会选择哪些线,来把这些具体的逻辑资源给连起来，形成一个真正可以工作的一个整体。"}
{"wav_id": "43", "speaker": "43", "offset": "320.570", "duration": "5.690", "wav": "43.wav", "translation": "For FPGAs, there are two important KPIs, namely resource consumption and working frequency.", "transcript": "那对于这FPGA来说，其实有两个重要的指标，一个就是资源的消耗，一个就是工作的频率。"}
{"wav_id": "43", "speaker": "43", "offset": "326.610", "duration": "2.990", "wav": "43.wav", "translation": "Suppose you want to implement a specific algorithm, such as this matrix multiplication.", "transcript": "假设你要实现一个具体的算法，例如说这是一个矩阵乘法。"}
{"wav_id": "43", "speaker": "43", "offset": "330.200", "duration": "6.230", "wav": "43.wav", "translation": "Your resource consumption will determine whether your design is good or bad.", "transcript": "你消耗的咯资源多还是少，就决定了你这个设计是不是一个优秀的设计，还是一个不好的设计。"}
{"wav_id": "43", "speaker": "43", "offset": "336.820", "duration": "2.470", "wav": "43.wav", "translation": "At the same time, the working frequency is important.", "transcript": "同时你的工作频率到底有多高。"}
{"wav_id": "43", "speaker": "43", "offset": "339.340", "duration": "7.000", "wav": "43.wav", "translation": "If, for the same design, my working frequency is 500M and yours is only 200M, then my design's performance will be more than twice higher than yours.", "transcript": "假设同样一个设计，我可以做到500兆，但你只能只能做到200兆，那我就性能就比你高出来一倍多。"}
{"wav_id": "43", "speaker": "43", "offset": "346.770", "duration": "3.890", "wav": "43.wav", "translation": "Therefore, these two KPIs are critical for FPGA design.", "transcript": "所以说这两个指标是对FPGA设计来说最关键的两个指标。"}
{"wav_id": "43", "speaker": "43", "offset": "352.650", "duration": "3.060", "wav": "43.wav", "translation": "What are the advantages of FPGAs?", "transcript": "呃那FPGA有什么优势呢？"}
{"wav_id": "43", "speaker": "43", "offset": "356.150", "duration": "5.060", "wav": "43.wav", "translation": "Just now, I mentioned that there are many logic cells in an FPGA.", "transcript": "就是刚才也讲FPGA里面有非常多的这种呃逻辑单元。"}
{"wav_id": "43", "speaker": "43", "offset": "361.450", "duration": "16.460", "wav": "43.wav", "translation": "Today, a large FPGA, such as the 20nm KU115, the 16nm VU9P or the 14nm Stratix 10, has millions of registers, thousands of DSPs, and dozens of megabytes of on-chip SRAM.", "transcript": "现在一一个大型的FPGA，像20纳米的ku115，然后再16纳米的VU9P或者说是Stratix 10 14纳米的，里面都有十十十几百万个寄存器，然后有几千个DSP，有几十兆的片内的SRAM。"}
{"wav_id": "43", "speaker": "43", "offset": "378.000", "duration": "3.260", "wav": "43.wav", "translation": "With so many resources, it is highly suitable for parallel computing.", "transcript": "这么多的资源，它实际上是非常适合并行计算。"}
{"wav_id": "43", "speaker": "43", "offset": "382.100", "duration": "6.110", "wav": "43.wav", "translation": "Therefore, FPGAs are used in large-scale parallel computing scenarios such as AI.", "transcript": "所以说FPGA会用在很AI这种非常能大规模并行的这些场景。"}
{"wav_id": "43", "speaker": "43", "offset": "388.840", "duration": "2.280", "wav": "43.wav", "translation": "It is also highly suitable for processing high-speed data streams.", "transcript": "同时它也非常适合高速数据流的一个处理。"}
{"wav_id": "43", "speaker": "43", "offset": "391.480", "duration": "5.690", "wav": "43.wav", "translation": "Because an FPGA has many internal resources, it is very suitable for stream processing, such as the internal pipelining of data streams.", "transcript": "因为FPGA内部的资源非常多，它非常适合这种数据流的内部就Pipeline的这种流式处理。"}
{"wav_id": "43", "speaker": "43", "offset": "398.010", "duration": "15.550", "wav": "43.wav", "translation": "Because an FPGA is a specific circuit structure, the latency of each row and level during data stream processing is highly exact, predictable, and stable.", "transcript": "呃第三点它FPGA因为它是一个具体的电路结构，所以说我们可以对这个数据流的处理，每一排每一级的延时非常确定，而且非常可预测的，那它的稳定性就非常的高。"}
{"wav_id": "43", "speaker": "43", "offset": "413.620", "duration": "2.580", "wav": "43.wav", "translation": "Therefore, we often use FPGAs to process critical tasks.", "transcript": "所以我们会经常用FPGA来处理一些关键的任务。"}
{"wav_id": "43", "speaker": "43", "offset": "416.500", "duration": "4.470", "wav": "43.wav", "translation": "In Baidu's driverless car project, the latency must be exact and stay low.", "transcript": "像在百度的无人车里面，我对这个延时要非常地确定、非常地低。"}
{"wav_id": "43", "speaker": "43", "offset": "421.260", "duration": "3.050", "wav": "43.wav", "translation": "In this case,  FPGAs are preferable to other processors.", "transcript": "这时候FPGA就会比其他的处理器有更大的优势。"}
{"wav_id": "43", "speaker": "43", "offset": "425.340", "duration": "1.520", "wav": "43.wav", "translation": "The fourth advantage is their flexible I/O.", "transcript": "第四点呢是I/O很灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "428.090", "duration": "10.960", "wav": "43.wav", "translation": "We can connect FPGAs to CPUs or many other sensors such as cameras, LiDARs, and radars to form complex single-chip systems.", "transcript": "我可以把FPGA跟CPU连在一起，我也可以把FPGA跟很多传感器连在一起，跟Camera、跟LIDAR、RADAR等等等等，我就可以组成一个非常复杂的一个单片的一个系统。"}
{"wav_id": "43", "speaker": "43", "offset": "439.950", "duration": "3.590", "wav": "43.wav", "translation": "In addition, we can also customize our own processors to suit the application.", "transcript": "同时我们也可以针对应用来定制我们自己的处理器。"}
{"wav_id": "43", "speaker": "43", "offset": "443.610", "duration": "4.480", "wav": "43.wav", "translation": "We can create a very flexible system by putting a few small CPUs in an FPGA.", "transcript": "实现一些小的FP小的CPU在FPGA里面，让整个系统非常地灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "448.770", "duration": "3.390", "wav": "43.wav", "translation": "While it has many advantages, it naturally also has its shortcomings.", "transcript": "那有那么多的优势，那它必然也会有自己的不足。"}
{"wav_id": "43", "speaker": "43", "offset": "452.600", "duration": "3.060", "wav": "43.wav", "translation": "The first shortcoming is that its development cycle is very long.", "transcript": "第一个不足，我觉得最关键的就是它的开发周期还是非常长的。"}
{"wav_id": "43", "speaker": "43", "offset": "456.520", "duration": "2.530", "wav": "43.wav", "translation": "Just now, I said that FPGA development is different from CPU development.", "transcript": "刚才也讲FPGA的开发跟CPU开发不一样。"}
{"wav_id": "43", "speaker": "43", "offset": "459.100", "duration": "4.520", "wav": "43.wav", "translation": "For CPUs, you only need to convert a high-level language into instructions for execution.", "transcript": "CPU你只要把高层次的语言转化成指令，就可以运行了。"}
{"wav_id": "43", "speaker": "43", "offset": "464.000", "duration": "6.070", "wav": "43.wav", "translation": "Since the circuit structure of a CPU is fixed, you only need to create instructions according to this circuit structure.", "transcript": "因为它CPU的电路结构是固定的，你只需要按照它的电路结构来生成指令就可以。"}
{"wav_id": "43", "speaker": "43", "offset": "470.600", "duration": "7.230", "wav": "43.wav", "translation": "However, for FPGAs, we need to perform two additional steps for the language to eventually be transmitted to the circuit structure, those being placement and routing.", "transcript": "但是FPGA来说，我要从语言到电路结构之间，我可要布还要布局和布线这两步。"}
{"wav_id": "43", "speaker": "43", "offset": "477.890", "duration": "6.120", "wav": "43.wav", "translation": "Because an FPGA has a lot of logic cells, it will take a long time to find the optimal layout and routing.", "transcript": "因为FPGA有那么多的逻辑逻辑单元，所以我要找一个最优解来做布局布线是非常耗时的。"}
{"wav_id": "43", "speaker": "43", "offset": "484.590", "duration": "1.630", "wav": "43.wav", "translation": "Therefore, the development cycle is very long.", "transcript": "所以这个开开发周期非常的长。"}
{"wav_id": "43", "speaker": "43", "offset": "486.910", "duration": "1.640", "wav": "43.wav", "translation": "Moreover, debugging is very difficult.", "transcript": "而且我Debug也很很困难。"}
{"wav_id": "43", "speaker": "43", "offset": "488.950", "duration": "5.350", "wav": "43.wav", "translation": "For CPU debugging, we can find problems easily by using GDB.", "transcript": "如果我要发我CPU Debug的话，我可以用G GDB很容易就能就找到这问题。"}
{"wav_id": "43", "speaker": "43", "offset": "495.010", "duration": "9.080", "wav": "43.wav", "translation": "But for FPGA debugging, we must use the manufacturer's JTAG cable to look at internal signals or use simulation to solve problems in some cases.", "transcript": "但是对对于FPGA这样一个电路来说，我要Debug的话，我必须用厂家的那个Jtag线来看里面的信号，或或者说有时候用仿真也能解决些问题。"}
{"wav_id": "43", "speaker": "43", "offset": "504.330", "duration": "2.870", "wav": "43.wav", "translation": "If simulation cannot solve the problem, we must check the board.", "transcript": "在仿真解决不了的情况下，我只能是上板来看。"}
{"wav_id": "43", "speaker": "43", "offset": "507.520", "duration": "1.220", "wav": "43.wav", "translation": "This is very difficult.", "transcript": "这个是非常困难的。"}
{"wav_id": "43", "speaker": "43", "offset": "509.300", "duration": "1.460", "wav": "43.wav", "translation": "In addition, there are time sequence challenges.", "transcript": "同时也会有时序的挑战。"}
{"wav_id": "43", "speaker": "43", "offset": "511.100", "duration": "2.750", "wav": "43.wav", "translation": "Suppose that our design goal is 500M.", "transcript": "就是假设我一个设设计的目标可能要达到500兆。"}
{"wav_id": "43", "speaker": "43", "offset": "514.120", "duration": "5.570", "wav": "43.wav", "translation": "However, as is usually the case, the first version is only 200M or 300M, which is far from our goal.", "transcript": "但是很经常第一版出来可能也就两三百兆，那离这个我们目标可能还有很大一段距离。"}
{"wav_id": "43", "speaker": "43", "offset": "519.740", "duration": "3.810", "wav": "43.wav", "translation": "We need to modify the design through iteration, optimize the time sequence, or take other actions.", "transcript": "那我们可能要迭代来修改设计，来做时序的调优等等。"}
{"wav_id": "43", "speaker": "43", "offset": "523.620", "duration": "0.800", "wav": "43.wav", "translation": "This is very time-consuming.", "transcript": "这个非常耗时。"}
{"wav_id": "43", "speaker": "43", "offset": "525.320", "duration": "7.930", "wav": "43.wav", "translation": "The second shortcoming is as follows: Unlike CPUs, CPUs use microinstructions, which can share the same circuit.", "transcript": "呃第二点就是，FPGA 因为它的电路是固定好的，它不像CPU那样，它是通过微指令，微指令之间可以复用同样一块电路。"}
{"wav_id": "43", "speaker": "43", "offset": "533.730", "duration": "4.370", "wav": "43.wav", "translation": "Conversely, FPGAs use fixed logic cells whose circuits are statically divided.", "transcript": "但是我FPGA是固定静态划分好电路的逻辑单元。"}
{"wav_id": "43", "speaker": "43", "offset": "538.510", "duration": "4.420", "wav": "43.wav", "translation": "Assume that we assign a logic block to function A.", "transcript": "所以说我要做假设我一块单元我一个功能给了Function A。"}
{"wav_id": "43", "speaker": "43", "offset": "543.450", "duration": "2.870", "wav": "43.wav", "translation": "This logic block then can be used only by function A, but not by function B.", "transcript": "它就只能给A来做，它B就不能再用那块功能。"}
{"wav_id": "43", "speaker": "43", "offset": "547.120", "duration": "1.490", "wav": "43.wav", "translation": "It exclusively occupies that logical block.", "transcript": "所以它就独占了那块逻辑。"}
{"wav_id": "43", "speaker": "43", "offset": "548.880", "duration": "2.880", "wav": "43.wav", "translation": "Therefore, the operator switchover is not as flexible as that in CPUs and GPUs.", "transcript": "所以我的算子切换实际上没有CPU和GPU那么灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "553.860", "duration": "4.620", "wav": "43.wav", "translation": "Next, I will talk about the characteristics of deep learning, from the perspective of computing.", "transcript": "那接下来我会讲一下深度学习有哪些特点，在计算上哪些特点。"}
{"wav_id": "43", "speaker": "43", "offset": "558.940", "duration": "7.400", "wav": "43.wav", "translation": "As shown in this picture, there are three typical applications,  or in other words, three typical computing scenarios for deep learning.", "transcript": "大家可以看那个图，其实深度学习来说有三个非常典型的应用，呃或者说有非常三个非常典型的计算场景。"}
{"wav_id": "43", "speaker": "43", "offset": "566.810", "duration": "2.190", "wav": "43.wav", "translation": "The first one is the training in data centers.", "transcript": "第一个就是我们的数据中心的训练。"}
{"wav_id": "43", "speaker": "43", "offset": "569.720", "duration": "10.350", "wav": "43.wav", "translation": "After we have collected a lot of training data, our algorithm engineers will design sophisticated models so that the data can be used to train out excellent models.", "transcript": "就是我们会搜集到很多的训练的数据，然后我们算法工程师会设计出来非常精巧的模型，通过这个数据把这个模，然后训练出来一个很好的一个模型。"}
{"wav_id": "43", "speaker": "43", "offset": "580.150", "duration": "1.990", "wav": "43.wav", "translation": "These are all done in the data centers.", "transcript": "在这个都在数据中心里面来完成的。"}
{"wav_id": "43", "speaker": "43", "offset": "582.850", "duration": "5.440", "wav": "43.wav", "translation": "After completing a model, we will distribute it to our online large-scale servers.", "transcript": "完成之后我们会把这个模型分发到我们在线的服的那个服大规模的机器上。"}
{"wav_id": "43", "speaker": "43", "offset": "588.520", "duration": "6.470", "wav": "43.wav", "translation": "For example, if we want to sort web pages, we will provide a specific model.", "transcript": "例如说我们假如说我们会做呃网页的排序，那我们也会给一个模型来做网页的排序。"}
{"wav_id": "43", "speaker": "43", "offset": "595.160", "duration": "3.630", "wav": "43.wav", "translation": "If we want to do advertising, we will introduce our technical models to advertisers.", "transcript": "我们如果我们要做广告，那我们也会给广告宣传说我们技能模型。"}
{"wav_id": "43", "speaker": "43", "offset": "599.280", "duration": "5.830", "wav": "43.wav", "translation": "The computing scale of the online system is usually larger than that for offline training because there are two demands on an online system.", "transcript": "那这个在线的系统往往会比离线的训练会更大，因为在线有两个需求。"}
{"wav_id": "43", "speaker": "43", "offset": "605.310", "duration": "6.590", "wav": "43.wav", "translation": "First, it has to respond directly to user requests, for which low latency and high service quality are very important.", "transcript": "一方面就是我要直接响应用户的请求，它对这个延时和和服务的质量非常重要。"}
{"wav_id": "43", "speaker": "43", "offset": "612.200", "duration": "2.060", "wav": "43.wav", "translation": "Besides, the user scale is usually very large.", "transcript": "第二的话它一般用户的规模非常的大。"}
{"wav_id": "43", "speaker": "43", "offset": "614.310", "duration": "8.160", "wav": "43.wav", "translation": "Baidu search and other Baidu services receive a large number of user requests every day, and thus need the support of large-scale clusters.", "transcript": "像百度的整个搜索以及百度其他业务，每天会有非常大量的这个用户的请求进来，所以是它非常需要大规模的集群来支持。"}
{"wav_id": "43", "speaker": "43", "offset": "623.270", "duration": "3.780", "wav": "43.wav", "translation": "Besides data centers, there is another online application scenario, that is, terminals.", "transcript": "除了数据中心之外，还一个在线应用的场景，那就是端。"}
{"wav_id": "43", "speaker": "43", "offset": "627.500", "duration": "12.340", "wav": "43.wav", "translation": "AI will enable many, many terminals by granting them unimaginable comprehension and perception capabilities.", "transcript": "端的话，今天我们讲人工智能，实际上人工智能会赋能很多很多的端，让让让这个些端也产生一些意想不到的这种呃理解和这种感知的能力。"}
{"wav_id": "43", "speaker": "43", "offset": "640.140", "duration": "4.900", "wav": "43.wav", "translation": "The Baidu driverless car is a typical AI terminal.", "transcript": "像百度的无人车，这是我们在里面这是一个非常典型的人工智能的一个终端。"}
{"wav_id": "43", "speaker": "43", "offset": "645.400", "duration": "10.080", "wav": "43.wav", "translation": "In addition, our AI algorithms are used in such scenarios as face recognition turnstile and DuerOS-powered smart home devices.", "transcript": "同时我们像人脸的闸机，一些DuerOS用在的那些呃家庭的智能设备，这些场景里面都会运行着我们人工智能的算法。"}
{"wav_id": "43", "speaker": "43", "offset": "656.320", "duration": "7.050", "wav": "43.wav", "translation": "The three basic application scenarios of AI are training in data centers, online services in data centers, and intelligent devices.", "transcript": "所以说基本上人工智能的三个场景，数据中心的训练、数据中心的在线服务以及智能终端。"}
{"wav_id": "43", "speaker": "43", "offset": "664.950", "duration": "2.290", "wav": "43.wav", "translation": "I just talked about three scenarios.", "transcript": "那刚才讲的那个三个场景。"}
{"wav_id": "43", "speaker": "43", "offset": "667.330", "duration": "5.960", "wav": "43.wav", "translation": "Let's take a look at some of the core AI algorithms.", "transcript": "但我我们回头来看这个AI的一些计算的一些核心的算法。"}
{"wav_id": "43", "speaker": "43", "offset": "673.980", "duration": "4.150", "wav": "43.wav", "translation": "In the upper left corner, there is a typical DNN algorithm.", "transcript": "呃包括左上角的是这种非常经典的DNN。"}
{"wav_id": "43", "speaker": "43", "offset": "679.100", "duration": "4.050", "wav": "43.wav", "translation": "In the lower left corner, there is a typical CNN algorithm.", "transcript": "然后呃左下角的是非常经典的CNN。"}
{"wav_id": "43", "speaker": "43", "offset": "683.440", "duration": "2.610", "wav": "43.wav", "translation": "On the right, there are RNN and LSTM algorithms.", "transcript": "还有右边的是RNN 和LSTM。"}
{"wav_id": "43", "speaker": "43", "offset": "686.420", "duration": "13.060", "wav": "43.wav", "translation": "From these typical system and core algorithms, we can abstract the core operators, that is, matrix multiplication and convolution, which is usually used in CNN.", "transcript": "无论这几种这是典型的系统核心的算法里面，我们可以抽象出来，最核心的算法计算算子，其实就是矩阵的乘法和卷积，卷积在CNN里面用的比较多。"}
{"wav_id": "43", "speaker": "43", "offset": "699.850", "duration": "7.380", "wav": "43.wav", "translation": "Matrix multiplication, including vector-vector multiplication, is commonly used in DNN, LSTM, and RNN.", "transcript": "然后矩阵乘法，包括向量乘向量这种呃计算，在DNN 、LSTM和RNN里面用的比较普遍。"}
{"wav_id": "43", "speaker": "43", "offset": "707.650", "duration": "12.460", "wav": "43.wav", "translation": "Aside from these major operators, there may be some typical operators such as activation functions, image-related cropping, stitching, pooling, etc.", "transcript": "那除了这些大的算子之外，可能还会有一些像呃激活函数，还有像一些跟图像相关的裁剪、拼接、Pooling等等等等，这些是一些呃比较典型的算子。"}
{"wav_id": "43", "speaker": "43", "offset": "720.940", "duration": "7.230", "wav": "43.wav", "translation": "If we want to design AI accelerators, we only need to accelerate these common operators to complete most of the computing tasks.", "transcript": "所以我们如果要做AI的加速器，实际上我只需要针对这些比较普遍的算子来做加速，其实就能完成大部分的计算任务。"}
{"wav_id": "43", "speaker": "43", "offset": "729.730", "duration": "2.090", "wav": "43.wav", "translation": "We've talked about two points.", "transcript": "那我刚才讲了两点。"}
{"wav_id": "43", "speaker": "43", "offset": "731.880", "duration": "6.890", "wav": "43.wav", "translation": "Next, I will explain why FPGAs can excellently accelerate AI computing.", "transcript": "那我们第三点会有说，为什么FPGA能计算加速AI的这个任务，而且能做得很好？"}
{"wav_id": "43", "speaker": "43", "offset": "740.290", "duration": "2.690", "wav": "43.wav", "translation": "Let's take a look from another perspective.", "transcript": "呃会从另外一个角度来讲。"}
{"wav_id": "43", "speaker": "43", "offset": "743.100", "duration": "2.120", "wav": "43.wav", "translation": "First of all are the advantages of FPGA.", "transcript": "首先FPGA的优势。"}
{"wav_id": "43", "speaker": "43", "offset": "745.410", "duration": "6.300", "wav": "43.wav", "translation": "First, its process technology uses the latest technology.", "transcript": "第一点，它的工艺还是能紧紧跟上这个工最新的这种工艺的。"}
{"wav_id": "43", "speaker": "43", "offset": "751.800", "duration": "1.870", "wav": "43.wav", "translation": "There are only two FPGA manufacturers at present.", "transcript": "现在FPGA有两个厂家。"}
{"wav_id": "43", "speaker": "43", "offset": "754.030", "duration": "8.370", "wav": "43.wav", "translation": "The first is Intel, which bought Altera two years ago, so it now has its own FPGA product line.", "transcript": "第一个就是Intel，Intel大概是两年前买了Altera，所以说它现在它自己有FPGA产品线。"}
{"wav_id": "43", "speaker": "43", "offset": "762.880", "duration": "3.250", "wav": "43.wav", "translation": "The second is Xilinx, which is the inventor of FPGAs.", "transcript": "第二家就是Xilinx，Xilinx也是FPGA的发明者。"}
{"wav_id": "43", "speaker": "43", "offset": "766.620", "duration": "3.860", "wav": "43.wav", "translation": "It has almost forty years of history in the field of FPGAs, and it leads the industry.", "transcript": "在FPGA这个领域上，有三四十年的历史，非常领先。"}
{"wav_id": "43", "speaker": "43", "offset": "771.050", "duration": "2.760", "wav": "43.wav", "translation": "Both of them are doing very well.", "transcript": "那这两家其实都做得非常的不错。"}
{"wav_id": "43", "speaker": "43", "offset": "774.220", "duration": "6.240", "wav": "43.wav", "translation": "They provide the latest process technologies and use them in FPGA products once possible.", "transcript": "它们都会提供最新的工艺，就是基本上最新的工艺都会最早用在FPGA的产品上。"}
{"wav_id": "43", "speaker": "43", "offset": "780.890", "duration": "6.400", "wav": "43.wav", "translation": "Intel plans to release its 14nm Stratix 10 FPGAs in 2017.", "transcript": "像我在今年2017年，Intel会发布它的14纳米的Stratix 10的FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "787.830", "duration": "6.810", "wav": "43.wav", "translation": "It will also release 20nm MCPs, which integrates 20nm A10 FPGAs into general-purpose processors.", "transcript": "同时它也会发布20纳米的MCP，就是把20纳米的A10 FPGA整合到日常处理器里面。"}
{"wav_id": "43", "speaker": "43", "offset": "795.310", "duration": "3.840", "wav": "43.wav", "translation": "Xilinx will release the 16nm VU9P this year.", "transcript": "那对于Xilinx来说，今年它会发布16纳米的VU9P。"}
{"wav_id": "43", "speaker": "43", "offset": "799.200", "duration": "6.470", "wav": "43.wav", "translation": "It actually released the 16nm SOC version last year.", "transcript": "这么一个大的FPGA，那Xilinx实际上它的16纳米在去年就已经发布那个SOC的版本。"}
{"wav_id": "43", "speaker": "43", "offset": "806.360", "duration": "7.940", "wav": "43.wav", "translation": "In the next year, FPGAs will undergo a great change, for both companies will launch FPGAs with HBM.", "transcript": "在明年的话，FPGA还会有一个非常大的一个变革，就是会带HBM，这两家都会推出HBM的FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "814.770", "duration": "2.490", "wav": "43.wav", "translation": "HBM is short for High Bandwidth Memory.", "transcript": "HBM就是High Bandwidth Memory的意思。"}
{"wav_id": "43", "speaker": "43", "offset": "817.710", "duration": "9.990", "wav": "43.wav", "translation": "The memory bandwidth will be between several hundred gigabytes per second and one terabyte per second.", "transcript": "就说我在那个Memory的带宽会在几百Gigabit per second到一千Gigabit per second之间。"}
{"wav_id": "43", "speaker": "43", "offset": "827.930", "duration": "1.790", "wav": "43.wav", "translation": "This is a very large bandwidth.", "transcript": "这是一个非常大的一个带宽。"}
{"wav_id": "43", "speaker": "43", "offset": "829.780", "duration": "3.840", "wav": "43.wav", "translation": "It is basically an order of magnitude higher than the current server bandwidth.", "transcript": "基本上会比现在服务器的带宽高了整整一个数量级。"}
{"wav_id": "43", "speaker": "43", "offset": "834.200", "duration": "8.510", "wav": "43.wav", "translation": "HBM is integrated into the FPGA, which is beneficial to the FPGA PCB and power consumption.", "transcript": "而且HBM是整合在FPGA里面去的,所以对FPGA的呃做做PCB也好，对它的功耗也好。"}
{"wav_id": "43", "speaker": "43", "offset": "842.910", "duration": "1.670", "wav": "43.wav", "translation": "This is a very good improvement.", "transcript": "都会有非常好的一个改进。"}
{"wav_id": "43", "speaker": "43", "offset": "845.750", "duration": "9.900", "wav": "43.wav", "translation": "By around 2019, Intel will release 14nm MCP products.", "transcript": "那到了19年左右，Intel就会发布14纳米的的这样的一个MCP的这样一个一个产品。"}
{"wav_id": "43", "speaker": "43", "offset": "856.200", "duration": "6.160", "wav": "43.wav", "translation": "By 2019 or 2020, the FPGA process technology will evolve to 10nm and 7nm through iteration.", "transcript": "那到19年或者20年，那FPGA的新的工艺就会迭代到10纳米和7纳米。"}
{"wav_id": "43", "speaker": "43", "offset": "863.180", "duration": "4.300", "wav": "43.wav", "translation": "So you can see that FPGA process technologies follow the latest technologies.", "transcript": "所以说大家看这个FPGA的工艺，是紧紧地跟着最新的工艺来发展的。"}
{"wav_id": "43", "speaker": "43", "offset": "867.870", "duration": "6.000", "wav": "43.wav", "translation": "It guarantees that new process technologies can be used to solve problems for new applications.", "transcript": "所以也就保证了，如果有一些新的应用，我就能用新的工艺来解决它的问题。"}
{"wav_id": "43", "speaker": "43", "offset": "875.520", "duration": "1.540", "wav": "43.wav", "translation": "The second advantage is its architecture.", "transcript": "第二个优势就是它的架构。"}
{"wav_id": "43", "speaker": "43", "offset": "877.300", "duration": "7.100", "wav": "43.wav", "translation": "Just now, I mentioned that an FPGA has a lot of logic resources such as DSPs, BRAMs, and registers.", "transcript": "刚才我也讲FPGA里面有大量的逻辑资源，DSP、BRAM、寄存器，非常非常丰富的资源。"}
{"wav_id": "43", "speaker": "43", "offset": "884.780", "duration": "2.350", "wav": "43.wav", "translation": "These resources are very suitable for AI computing.", "transcript": "而且这些资源都是非常适合AI计算的。"}
{"wav_id": "43", "speaker": "43", "offset": "887.880", "duration": "6.670", "wav": "43.wav", "translation": "In addition to these rich resources, the FPGA micro-architecture is also very innovative.", "transcript": "那除了这些丰富的资源之外，其实FPGA它的微架构架构的创新也非常的活跃。"}
{"wav_id": "43", "speaker": "43", "offset": "895.310", "duration": "7.730", "wav": "43.wav", "translation": "As we mentioned before, although our process technology is evolving continuously, the development speed is not as fast as it used to be.", "transcript": "刚才也讲，虽然我们的工艺是在还是在不断地发展的，但是实际上工艺发展是没有以前那么快。"}
{"wav_id": "43", "speaker": "43", "offset": "903.350", "duration": "5.490", "wav": "43.wav", "translation": "During the early phase, a new version was iterated every 18  or 24 months according to Moore's law.", "transcript": "可能以前呃摩尔定律的推动下18个月或者24个月它会迭代一版。"}
{"wav_id": "43", "speaker": "43", "offset": "909.050", "duration": "4.760", "wav": "43.wav", "translation": "Now, it takes two, two-plus, three, or even four years to launch a new node.", "transcript": "现在可能要到两年、两年多，三年或者甚至四年，才会有一个新的节点出来。"}
{"wav_id": "43", "speaker": "43", "offset": "914.210", "duration": "8.850", "wav": "43.wav", "translation": "In recent years, FPGA manufacturers have found many new ways of creating innovative architectures and micro-architectures to drive the continuous evolution of FPGAs.", "transcript": "所以说FPGA厂家实际上是这几年从架构和微架构的创建上找到很多新的方法来推动FPGA的继续往前走。"}
{"wav_id": "43", "speaker": "43", "offset": "924.080", "duration": "5.260", "wav": "43.wav", "translation": "The second point is that there are new applications such as AI and data center services now.", "transcript": "第二点就是其实现在有新的应用，像AI、数据中心的业务。"}
{"wav_id": "43", "speaker": "43", "offset": "929.440", "duration": "5.560", "wav": "43.wav", "translation": "Driven by these new services,  as well as by opportunities brought about by GPUs, a lot of innovations have been made for FPGAs.", "transcript": "在这些新的业务大力推动下，以及在GPU的刺激上，现在FPGA也做了非常多的创新。"}
{"wav_id": "43", "speaker": "43", "offset": "935.580", "duration": "10.550", "wav": "43.wav", "translation": "For example, Intel added HBMs to FPGAs, and then integrated FPGAs with CPUs to form MCPs.", "transcript": "例如说Intel的FPGA里面会加进去这个HBM memory，然后会把FPGA跟CPU融合在一起，组成一个MCP的一个整体的一个芯片。"}
{"wav_id": "43", "speaker": "43", "offset": "946.550", "duration": "3.390", "wav": "43.wav", "translation": "This will greatly broaden the application scenarios of FPGA.", "transcript": "这个对FPGA的应用场景会大大地拓宽。"}
{"wav_id": "43", "speaker": "43", "offset": "950.460", "duration": "4.610", "wav": "43.wav", "translation": "In addition, FPGAs provide hard floating point and rich and flexible DSPs.", "transcript": "同时FPGA里面也提供了硬的浮点，提供了非常丰富而非常灵活的DSP。"}
{"wav_id": "43", "speaker": "43", "offset": "955.670", "duration": "2.260", "wav": "43.wav", "translation": "Xilinx will also provide HBMs.", "transcript": "Xilinx也一样，它也会提供HBM。"}
{"wav_id": "43", "speaker": "43", "offset": "958.310", "duration": "2.650", "wav": "43.wav", "translation": "In addition, they will provide massive ultra-memories.", "transcript": "它会而且它会提供非常大的ultra memory。"}
{"wav_id": "43", "speaker": "43", "offset": "961.310", "duration": "4.860", "wav": "43.wav", "translation": "The capacity of an on-chip ultraRAM can reach tens of megabytes. This is essentially an SRAM with huge data flows.", "transcript": "在一个ultraRAM在片内能达到几十兆Byte这样一个非常大流量的SRAM。"}
{"wav_id": "43", "speaker": "43", "offset": "966.680", "duration": "8.720", "wav": "43.wav", "translation": "This is very useful for buffering AI parameters and input data and performing data locality.", "transcript": "这个对于缓存AI的参数，缓存输入的数据，做对数据的Locality，非常有帮助。"}
{"wav_id": "43", "speaker": "43", "offset": "975.940", "duration": "2.500", "wav": "43.wav", "translation": "It also provides rich and flexible DSPs.", "transcript": "它也提供非常丰富而且非常灵活的DSP。"}
{"wav_id": "43", "speaker": "43", "offset": "978.890", "duration": "6.300", "wav": "43.wav", "translation": "There are some details of the architecture that cannot be disclosed because of the NDAs with the manufacturers.", "transcript": "这里面当然还有一些细节的架构，可能涉及到跟厂家之间的一些NDA，就不方便讲。"}
{"wav_id": "43", "speaker": "43", "offset": "985.280", "duration": "7.610", "wav": "43.wav", "translation": "With the release of new products, you will see more exciting features.", "transcript": "但是随着它们产品的发布，大家还可以看到更多更激动人心的一些Feature出来。"}
{"wav_id": "43", "speaker": "43", "offset": "993.110", "duration": "5.730", "wav": "43.wav", "translation": "These new features will greatly consolidate the advantages of FPGAs in AI computing.", "transcript": "这些新的Feature都会极大地帮助FPGA巩固在AI计算里面的一些优势。"}
{"wav_id": "43", "speaker": "43", "offset": "1001.390", "duration": "6.360", "wav": "43.wav", "translation": "In conclusion, in the FPGA architecture, every subsystem is excellent.", "transcript": "那我们总结一下这FPGA的架构，每个子系统其实都都非常的做得非常的好。"}
{"wav_id": "43", "speaker": "43", "offset": "1008.080", "duration": "5.870", "wav": "43.wav", "translation": "For example, for its memory subsystem, we can use HBMs to ensure high bandwidth.", "transcript": "像它的Memory子系统，我可以有HBM，我保证了这个Memory的带宽，非常的高。"}
{"wav_id": "43", "speaker": "43", "offset": "1014.590", "duration": "3.160", "wav": "43.wav", "translation": "The bandwidth is an order of magnitude higher than the CPU bandwidth, and is even higher than the GPU bandwidth.", "transcript": "比CPU要高一个量级，甚至比GPU还要高。"}
{"wav_id": "43", "speaker": "43", "offset": "1018.700", "duration": "4.570", "wav": "43.wav", "translation": "Moreover, we can have large-capacity on-chip SRAMs, which is not possible with any other chip.", "transcript": "而且我有大容量的片内SRAM ，这个是任何其他的芯片都做不到的。"}
{"wav_id": "43", "speaker": "43", "offset": "1023.550", "duration": "7.510", "wav": "43.wav", "translation": "The GPU has only a very small shared memory, specifically, a L2 cache of about two megabytes.", "transcript": "像GPU里面它只有非常小的share memory，还有非常小大概两兆byte这么大的L2 Cache,非常的小。"}
{"wav_id": "43", "speaker": "43", "offset": "1031.750", "duration": "4.610", "wav": "43.wav", "translation": "The L3 cache inside the CPU is about a dozen to thirty megabytes.", "transcript": "C CPU里面的Cache大概L3 Cache大概十几兆或三十几兆。"}
{"wav_id": "43", "speaker": "43", "offset": "1036.880", "duration": "2.860", "wav": "43.wav", "translation": "But its cache is not software controlled.", "transcript": "但是它的Cache是软件可不能不能控制的。"}
{"wav_id": "43", "speaker": "43", "offset": "1040.090", "duration": "8.300", "wav": "43.wav", "translation": "For a large FPGA, the on-chip SRAM is thirty-plus megabytes or even seventy or eighty megabytes, which is a lot.", "transcript": "那对于FPGA来说，声音大的FPGA，片内的SRAM，大概有30多兆或者再到七八十兆这样一个非常大一个量级。"}
{"wav_id": "43", "speaker": "43", "offset": "1048.820", "duration": "3.730", "wav": "43.wav", "translation": "Moreover, this large-capacity on-chip SRAM is software or circuit controllable.", "transcript": "而且这么大一个片内SRAM，都是软件电路可可控制的。"}
{"wav_id": "43", "speaker": "43", "offset": "1052.690", "duration": "1.080", "wav": "43.wav", "translation": "Therefore,  it can be used very flexibly.", "transcript": "用起来非常灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "1054.950", "duration": "1.650", "wav": "43.wav", "translation": "The second advantage is its computing subsystem.", "transcript": "第二点就是它的计算子系统。"}
{"wav_id": "43", "speaker": "43", "offset": "1057.940", "duration": "10.540", "wav": "43.wav", "translation": "An FPGA provides several thousands to over ten thousand variable-precision DSP blocks, which can be used to perform multiplication, addition, and accumulation with different precisions.", "transcript": "FPGA里面提供了非常多的大概有几千到一万多的这样一个可变精度的DSP，可以用来做不同精度的乘法、加法及乘累加。"}
{"wav_id": "43", "speaker": "43", "offset": "1068.940", "duration": "5.610", "wav": "43.wav", "translation": "In addition, we can use these DSP blocks to implement other complex calculations, activation functions, and so on.", "transcript": "而且我可以用这些DSP来实现非常复杂的其他的计算、激活函数等等等等。"}
{"wav_id": "43", "speaker": "43", "offset": "1075.880", "duration": "1.880", "wav": "43.wav", "translation": "Just now, I mentioned that FPGAs feature a very flexible architecture.", "transcript": "那刚才也讲了FPGA的架构很灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "1078.180", "duration": "2.300", "wav": "43.wav", "translation": "Therefore, the data path design is also very flexible.", "transcript": "所以说这个数据通路的设计也非常灵活。"}
{"wav_id": "43", "speaker": "43", "offset": "1080.540", "duration": "6.450", "wav": "43.wav", "translation": "It can be tightly coupled with the CPU, while we can also customize our own pipelines in the FPGA.", "transcript": "我可以跟CPU紧紧地耦合在一起，同时我也可以定制我自己的流水线在FPGA里面。"}
{"wav_id": "43", "speaker": "43", "offset": "1087.510", "duration": "4.490", "wav": "43.wav", "translation": "Let's take a look at the combined advantages of these three architectures.", "transcript": "那这三个架构的一个总综合来看它的优势。"}
{"wav_id": "43", "speaker": "43", "offset": "1092.040", "duration": "5.450", "wav": "43.wav", "translation": "First, we can pursue the ultimate performance through deep customization.", "transcript": "首先,如果我想深度地做定制，来追求极致的性能，我是可以做得到的。"}
{"wav_id": "43", "speaker": "43", "offset": "1098.240", "duration": "5.760", "wav": "43.wav", "translation": "Second, we can achieve a balance of performance, universality, and ease of use.", "transcript": "第二点，如果我想追求性能，通通用性以及易用性的一个平衡，我也是可以做得到的。"}
{"wav_id": "43", "speaker": "43", "offset": "1104.450", "duration": "16.120", "wav": "43.wav", "translation": "Unlike GPUs, which are only suitable for some forms of data computing but not for irregular computing and data analysis, FPGAs support diverse application scenarios.", "transcript": "或者说我要有非常多元的应用场景，FPGA也是能支持，它不像GPU，只能对一些数据计算可能比较合适，对一些其他的数据分析等等一些比较呃没那么规整的计算它就没做得没那么好，但FPGA这些都不存在。"}
{"wav_id": "43", "speaker": "43", "offset": "1121.610", "duration": "3.250", "wav": "43.wav", "translation": "I shall now talk about Baidu's practices over the past six years.", "transcript": "那这里就会开始讲一下百度在过去六年的一个实践。"}
{"wav_id": "43", "speaker": "43", "offset": "1125.280", "duration": "4.120", "wav": "43.wav", "translation": "Baidu started to work on FPGA-based AI acceleration projects around 2011 or 2012.", "transcript": "其实百度大概12年11年左右，就开始在做FPGA对AI的加速。"}
{"wav_id": "43", "speaker": "43", "offset": "1129.450", "duration": "1.390", "wav": "43.wav", "translation": "We might have been the first company to do so in the industry.", "transcript": "应该在业界是做得最早的。"}
{"wav_id": "43", "speaker": "43", "offset": "1131.340", "duration": "3.660", "wav": "43.wav", "translation": "At first, we used the 28nm Xilinx FPGA.", "transcript": "我们最开始用28纳米的FPGA，Xilinx的那个FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "1135.450", "duration": "8.770", "wav": "43.wav", "translation": "We eventually offered an FPGA with approximately 30W power consumption and 380Gops to 1.3Tops performance.", "transcript": "在FPGA大概我们最后做到30W左右的功耗，能做到380Gops到1.3Tops的这样一个性能。"}
{"wav_id": "43", "speaker": "43", "offset": "1145.100", "duration": "3.740", "wav": "43.wav", "translation": "At that time, this was the best performance efficiency in the industry.", "transcript": "在那个节点上应该是业界最领先的一个性能效率。"}
{"wav_id": "43", "speaker": "43", "offset": "1149.500", "duration": "4.210", "wav": "43.wav", "translation": "After 2015, we switched to the 20nm Xilinx FPGA.", "transcript": "那到15年之后，我们就切换到20纳米的Xilinx的FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "1154.420", "duration": "2.970", "wav": "43.wav", "translation": "With this FPGA, we also offered the best performance efficiency in the industry.", "transcript": "这个FPGA我们也基本上做到了业界最优的一个计算效能。"}
{"wav_id": "43", "speaker": "43", "offset": "1157.930", "duration": "8.980", "wav": "43.wav", "translation": "This year, 2017, we switched to a new generation of FPGAs of 14 or 16nm, which performance will be two to three times greater than  that of the old generation.", "transcript": "在17年的时的就就是今年我们切换到14或16纳米的新一代的FPGA，会带来大概一两到三倍的性能提高。"}
{"wav_id": "43", "speaker": "43", "offset": "1166.970", "duration": "3.070", "wav": "43.wav", "translation": "At the same time, its energy efficiency will be much greater.", "transcript": "同时能耗效率还会大大的提也会提高。"}
{"wav_id": "43", "speaker": "43", "offset": "1171.140", "duration": "1.860", "wav": "43.wav", "translation": "Let's take a look at the architecture diagram.", "transcript": "大家看这样一个架构图。"}
{"wav_id": "43", "speaker": "43", "offset": "1173.130", "duration": "5.760", "wav": "43.wav", "translation": "It is the same diagram described in our paper presented at Hot Chips in 2014.", "transcript": "基本上就是我们在2014年Hotchips上发表的那篇文章上讲的那个那个框图。"}
{"wav_id": "43", "speaker": "43", "offset": "1178.930", "duration": "3.200", "wav": "43.wav", "translation": "The left architecture is Baidu's SDA, or Software-Defined Accelerator.", "transcript": "左边是百度，我们叫SDA Software-Defined Accelerator。"}
{"wav_id": "43", "speaker": "43", "offset": "1182.690", "duration": "2.700", "wav": "43.wav", "translation": "This was a concept we proposed.", "transcript": "就我们提出了一个软件定义加速器这样一个概念。"}
{"wav_id": "43", "speaker": "43", "offset": "1185.980", "duration": "4.070", "wav": "43.wav", "translation": "This diagram clearly depicts the architecture of an AI accelerator.", "transcript": "这个框图其实就是非常直观的一个AI加速器的架构。"}
{"wav_id": "43", "speaker": "43", "offset": "1190.630", "duration": "4.480", "wav": "43.wav", "translation": "In reality, the data of the DMA on the left comes from the CPU.", "transcript": "呃它的最左边实际上DMA是从数据是从CPU里面过来的。"}
{"wav_id": "43", "speaker": "43", "offset": "1195.300", "duration": "4.450", "wav": "43.wav", "translation": "In the FPGA, we put the off-chip DDR3 or DDR4 memory.", "transcript": "那在FPGA里面，片外我们会放了DDR3和DDR4的memory。"}
{"wav_id": "43", "speaker": "43", "offset": "1200.390", "duration": "5.430", "wav": "43.wav", "translation": "On the chip, the core part is the vector ALU.", "transcript": "那在片内的话，我们最核心的部分就是向量的ALU。"}
{"wav_id": "43", "speaker": "43", "offset": "1206.220", "duration": "2.900", "wav": "43.wav", "translation": "We complete the vector multiply-accumulate calculation in the ALU.", "transcript": "我们会在在在ALU里面完成向量的乘累加计算。"}
{"wav_id": "43", "speaker": "43", "offset": "1209.620", "duration": "4.330", "wav": "43.wav", "translation": "There is another small function, that is, activation function and some other calculations.", "transcript": "然后还有一个小功能，当然就是做激活函数以及其他一些计算。"}
{"wav_id": "43", "speaker": "43", "offset": "1214.520", "duration": "4.520", "wav": "43.wav", "translation": "For the input and output of these computing units, we use a lot of on-chip SRAMs to buffer data.", "transcript": "那这些计算单元的输入和输出，我们都利用了大量的片内SRAM来做buffer。"}
{"wav_id": "43", "speaker": "43", "offset": "1219.510", "duration": "6.240", "wav": "43.wav", "translation": "The buffer ensures the reusability of data, greatly improving the computing efficiency and reducing the computing power consumption.", "transcript": "这个buffer是保障了数据能很好地复用，大大地提高了这个计算的效率，降低了计算的功耗。"}
{"wav_id": "43", "speaker": "43", "offset": "1226.460", "duration": "2.030", "wav": "43.wav", "translation": "We can compare this to the diagram on the right, which is a TPU.", "transcript": "大家可以对比一下右边那个图就是TPU。"}
{"wav_id": "43", "speaker": "43", "offset": "1228.580", "duration": "2.030", "wav": "43.wav", "translation": "This is the diagram described in the paper presented by Google this year.", "transcript": "Google在今年发表论文的一个图。"}
{"wav_id": "43", "speaker": "43", "offset": "1231.130", "duration": "2.220", "wav": "43.wav", "translation": "This diagram is similar to ours.", "transcript": "实际上看呢这个图还是非常像的。"}
{"wav_id": "43", "speaker": "43", "offset": "1233.830", "duration": "3.300", "wav": "43.wav", "translation": "It is a clear deep learning architecture.", "transcript": "就是非常直观的一种深度学习的这样一些架构。"}
{"wav_id": "43", "speaker": "43", "offset": "1237.550", "duration": "5.300", "wav": "43.wav", "translation": "It also uses a systolic array architecture to implement vector multiply-accumulate calculation and convolution calculation.", "transcript": "它也是用了一个脉动阵列的一个架构，来实现了向量的乘累加以及卷积的计算。"}
{"wav_id": "43", "speaker": "43", "offset": "1244.210", "duration": "7.140", "wav": "43.wav", "translation": "It uses activation function units to implement activation functions and uses a lot of on-chip buffers to perform data locality.", "transcript": "然后它也用了一些呃激活函数的单元来做激活函数，然后它也用了大量的片内的buffer来做Locality。"}
{"wav_id": "43", "speaker": "43", "offset": "1251.720", "duration": "7.290", "wav": "43.wav", "translation": "Hence, our proposed architecture in 2014 is similar to Google's proposed architecture in 2016 and 2017.", "transcript": "所以基本上这个架构非常的像，这是我们在14年的架构跟Google在16年17年的架构实际上是蛮像的。"}
{"wav_id": "43", "speaker": "43", "offset": "1261.240", "duration": "5.260", "wav": "43.wav", "translation": "At Hot Chips 2014, we released some of our data.", "transcript": "呃我们在14年Hotchips其实也都把我们当时做的一些数据都release出来。"}
{"wav_id": "43", "speaker": "43", "offset": "1266.790", "duration": "3.220", "wav": "43.wav", "translation": "Back then, we were using the 28nm FPGA.", "transcript": "当时我们用的是是是是呃28纳米的FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "1270.340", "duration": "8.920", "wav": "43.wav", "translation": "From the perspective of peak performance, the version we presented, which was our earliest version, offered only around 300 Gflops.", "transcript": "其实从峰值性能来看它嘶我们那个版本是一个大概只有300呃，最早那个版本我们出去讲的时候用的最早的那版本的数据。"}
{"wav_id": "43", "speaker": "43", "offset": "1279.630", "duration": "2.270", "wav": "43.wav", "translation": "In the later versions, the value became higher, but we did not publicize them.", "transcript": "但后来数据会更好，我们没有拿出来讲。"}
{"wav_id": "43", "speaker": "43", "offset": "1282.640", "duration": "11.110", "wav": "43.wav", "translation": "The 380Gflops performance was not even half of that of the K10 GPU, which could offer 1Tflops performance.", "transcript": "呃大概380Gflops的性能跟当时的K10的GPU来比是比不过的，大概连它的一半都不到，因为K10的GPU大概能做到1Tflops的性能。"}
{"wav_id": "43", "speaker": "43", "offset": "1294.870", "duration": "13.400", "wav": "43.wav", "translation": "In our real system, however, because the online application performance is different from the benchmark performance, the batch size of input data is often very small for online applications, which is different from the benchmark.", "transcript": "呃但是呢我们在实际的系统里面，我们在一个真实的一个我们线上的应用里面，因为线上应用跟做Benchmark不一样，线上应用很多时候我们会那个输入的数据Batch size会不会很小。"}
{"wav_id": "43", "speaker": "43", "offset": "1309.670", "duration": "5.210", "wav": "43.wav", "translation": "As I mentioned before, online applications must respond to user requests quickly.", "transcript": "呃因为我刚才也讲了线上应用我要我要请对用户的请求做出非常积极的响应。"}
{"wav_id": "43", "speaker": "43", "offset": "1315.320", "duration": "4.310", "wav": "43.wav", "translation": "Therefore, we cannot use large batch sizes, which will increase t latency.", "transcript": "所以说我就不能把那Batch size拼得特别大，那样会提高这个延时。"}
{"wav_id": "43", "speaker": "43", "offset": "1320.150", "duration": "3.130", "wav": "43.wav", "translation": "The batch size is usually 4 or 8, or 16 at most.", "transcript": "这个Batch size我们一般是4或者8或者最大就是16。"}
{"wav_id": "43", "speaker": "43", "offset": "1323.580", "duration": "1.190", "wav": "43.wav", "translation": "It is rarely greater than 16.", "transcript": "很少会大于16的。"}
{"wav_id": "43", "speaker": "43", "offset": "1325.420", "duration": "6.570", "wav": "43.wav", "translation": "Since the batch size is very small, our FPGA solution will obviously be better than the GPU solution.", "transcript": "所以在这么小的Batch size的情况下，我们的FPGA的方案就会明显优于GPU的方案。"}
{"wav_id": "43", "speaker": "43", "offset": "1332.350", "duration": "9.120", "wav": "43.wav", "translation": "We can see that the data throughput is about 3 to 4 times higher than that of the GPU, which is excellent.", "transcript": "基本上我们能看得到，这个吞吐会大概比GPU会好到3到4倍，非常非常好的一个数据。"}
{"wav_id": "43", "speaker": "43", "offset": "1341.920", "duration": "6.770", "wav": "43.wav", "translation": "Moreover, with only a power consumption of 30W, we are able to obtain values which GPUs would need 200W to obtain.", "transcript": "而且我们是在只有30瓦多的一个功耗上，比两百多瓦的GPU取得的这样一个数据。"}
{"wav_id": "43", "speaker": "43", "offset": "1348.790", "duration": "8.380", "wav": "43.wav", "translation": "Therefore, from the perspectives of performance, energy efficiency, and cost performance, FPGAs have obvious advantages over GPUs.", "transcript": "所以说这个无论是从性能、能耗效率还是性价比上显然FPGA都获得了比GPU非常好的这样一个优势。"}
{"wav_id": "43", "speaker": "43", "offset": "1358.870", "duration": "7.290", "wav": "43.wav", "translation": "In addition, we upgraded to the 20nm FPGA last year.", "transcript": "呃同时我们在去年的时候，因为我刚才也讲FPGA我们升级到了20纳米的的这样一个新的FPGA。"}
{"wav_id": "43", "speaker": "43", "offset": "1366.650", "duration": "8.150", "wav": "43.wav", "translation": "Using ResNet, we performed acceleration of a deep learning CNN application model on this FPGA.", "transcript": "那我们在这样一个FPGA上我们呃做了一个深度学习CNN的应用模型的加速，我们用ResNet来做测试。"}
{"wav_id": "43", "speaker": "43", "offset": "1375.230", "duration": "6.240", "wav": "43.wav", "translation": "At approximately 55W power consumption, the throughput reached 110fps.", "transcript": "呃在55瓦左右的功耗下我能达到110帧每秒的这样一个吞吐。"}
{"wav_id": "43", "speaker": "43", "offset": "1381.920", "duration": "10.260", "wav": "43.wav", "translation": "When we used the K40 GPU with approximately 235W power consumption, the throughput was only 58fps.", "transcript": "那对于GPU来说，我们当时用的是K40的GPU，大概235瓦的功耗，只能达到58帧每秒的这样一个计算吞吐。"}
{"wav_id": "43", "speaker": "43", "offset": "1392.620", "duration": "4.810", "wav": "43.wav", "translation": "Thus, the performance of the FPGA is 1.9 times better than that of the GPU.", "transcript": "所所以说FPGA能比GPU好1.9倍的性能。"}
{"wav_id": "43", "speaker": "43", "offset": "1398.080", "duration": "4.290", "wav": "43.wav", "translation": "Energy efficiency is almost 8 times better.", "transcript": "那如果算算能耗效率的话，基本上能达到八倍的一个能耗效率。"}
{"wav_id": "43", "speaker": "43", "offset": "1404.710", "duration": "9.790", "wav": "43.wav", "translation": "As you can see, Baidu's AI accelerator can offer better computing performance and higher energy efficiency than general-purpose circuit architectures.", "transcript": "大家可以看得到，通过这种呃我们百度自己研发的AI加速器，其实能比通用的电路结构能达到更高的计算性能、更好的能耗效率。"}
{"wav_id": "43", "speaker": "43", "offset": "1416.330", "duration": "12.710", "wav": "43.wav", "translation": "Baidu has done a lot of in-depth research in the past six years, and we are the leader in terms of academic output among Chinese companies.", "transcript": "呃我们百度在过去六年多时间，做了很多很深入的探索，同时我们在学术产出方面也是国内最领先的。"}
{"wav_id": "43", "speaker": "43", "offset": "1429.670", "duration": "11.070", "wav": "43.wav", "translation": "We presented three papers at Hot Chips, one of the leading chip industry conferences, in 2014, 2016, and 2017.", "transcript": "我们在最顶级的一个芯片的会议上叫Hotchips上，连续呃2014年、2016年、2017年三篇论文。"}
{"wav_id": "43", "speaker": "43", "offset": "1440.880", "duration": "10.570", "wav": "43.wav", "translation": "As Chinese companies presented seven or eight papers at Hot Chips, our papers accounted for 30-40 percent, or nearly half, of these papers.", "transcript": "基本上国内目前整个国内可能Hotchips会议上大概七八篇论文有差不多百分之三四十或接近一半是我们百度来发的。"}
{"wav_id": "43", "speaker": "43", "offset": "1452.440", "duration": "8.440", "wav": "43.wav", "translation": "This shows our strong technical influence in the field.", "transcript": "所以说这基本上奠定了我们在这一个领域上的一个很好的一个一个技技术的影响力。"}
{"wav_id": "43", "speaker": "43", "offset": "1461.240", "duration": "8.860", "wav": "43.wav", "translation": "This also proves that we are not just blowing our own trumpet, but rather that our work is recognized by the leading bodies in the industry.", "transcript": "这也说明我们做的工作是能得到业界最高水平的这个认可，而不是自己在这里呃自吹自擂的这样一个一个情况。"}
{"wav_id": "43", "speaker": "43", "offset": "1470.530", "duration": "6.290", "wav": "43.wav", "translation": "In terms of our work related to FPGA in earlier years, in addition, one of our papers was accepted at ASPLOS 2014.", "transcript": "同时，我们再往前，我们FPGA的工作其实也获得了ASPLOS 2014的论文的一个录取。"}
{"wav_id": "43", "speaker": "43", "offset": "1477.140", "duration": "3.750", "wav": "43.wav", "translation": "This was the second ASPLOS paper from China and the first paper from the industrial circle to be accepted.", "transcript": "这也是国内第二篇ASPLOS论文，工工业界的第一篇。"}
{"wav_id": "43", "speaker": "43", "offset": "1481.330", "duration": "2.600", "wav": "43.wav", "translation": "It was also the first Hot Chips paper from the industrial circle.", "transcript": "包括Hotchips也是我们也是工业界第一篇的Hotchips。"}
{"wav_id": "43", "speaker": "43", "offset": "1484.410", "duration": "5.020", "wav": "43.wav", "translation": "Before we presented the paper at Hot Chips, it was rare for Chinese companies to present papers there.", "transcript": "在我们发表Hotchips之前，其实国内也就非常少量的计算所发表过一些。"}
{"wav_id": "43", "speaker": "43", "offset": "1489.920", "duration": "5.760", "wav": "43.wav", "translation": "Our presenting of three successive papers had widespread influence internationally.", "transcript": "那百度像这个后面基本上连续发了三篇，这基本上在国际上也是非常大的一个影响力。"}
{"wav_id": "43", "speaker": "43", "offset": "1497.650", "duration": "7.400", "wav": "43.wav", "translation": "In reality, Baidu AI accelerator has been implemented excellently.", "transcript": "呃刚才讲了那么多，实际上百度的AI加速器的落地也做得非常的不错。"}
{"wav_id": "43", "speaker": "43", "offset": "1505.320", "duration": "6.510", "wav": "43.wav", "translation": "In my opinion, we have the largest application scale of the AI accelerator in the industry.", "transcript": "基本上在我看来是整个业界呃AI加速器落地最大规模的这样一个场景在百度。"}
{"wav_id": "43", "speaker": "43", "offset": "1512.580", "duration": "8.320", "wav": "43.wav", "translation": "Even compared to Google or Microsoft, we are not lagging behind in terms of application scale, popularity, and application depth.", "transcript": "你即使跟Google或跟Microsoft来比，我们在应用规模、应用的广泛度、应用的深度都是不落后的。"}
{"wav_id": "43", "speaker": "43", "offset": "1522.520", "duration": "4.500", "wav": "43.wav", "translation": "In the past few years, FPGA accelerators have been widely used in many of our internal services.", "transcript": "呃我们过去几年，FPGA加速器在我们内部的业务上用了很多。"}
{"wav_id": "43", "speaker": "43", "offset": "1527.400", "duration": "8.640", "wav": "43.wav", "translation": "Beginning from this year, we will provide FPGA and AI accelerator capabilities via Baidu Cloud.", "transcript": "那在今年开始，我们会通过百度云对外提供我们这样一个FPGA的这样一个能力、AI加速器的能力。"}
{"wav_id": "43", "speaker": "43", "offset": "1536.460", "duration": "7.240", "wav": "43.wav", "translation": "We will offer cloud-based FPGA service packages, FPGA AI inference services, and even FPGA training services.", "transcript": "就包括我们会提供FPGA云的套餐，会提供FPGA AI inference的服务，甚至是FPGA Training的服务。"}
{"wav_id": "43", "speaker": "43", "offset": "1544.070", "duration": "4.380", "wav": "43.wav", "translation": "We will also provide services for multimedia,  biological information, AI acceleration, and more.", "transcript": "我们还会提供多媒体、生物信息、AI加速等等等等很多服务。"}
{"wav_id": "43", "speaker": "43", "offset": "1548.830", "duration": "3.800", "wav": "43.wav", "translation": "In addition, we will support private clouds.", "transcript": "同时我们也会支持私有云的模式，因为我们看得到。"}
{"wav_id": "43", "speaker": "43", "offset": "1554.060", "duration": "6.430", "wav": "43.wav", "translation": "I said just now that AI computing will not only be used on a large scale in data centers, but also on terminals.", "transcript": "刚才我也讲AI计算不光在数据中心上会大规模地用，在端的场景上也会大规模地用。"}
{"wav_id": "43", "speaker": "43", "offset": "1560.790", "duration": "3.010", "wav": "43.wav", "translation": "Therefore, we will provide services for terminal scenarios.", "transcript": "所以我们会提供这种端的场景下的这这些服务。"}
{"wav_id": "43", "speaker": "43", "offset": "1565.390", "duration": "4.660", "wav": "43.wav", "translation": "I shall now summarize why FPGAs are suitable for AI computing.", "transcript": "呃最后我总结一下，呃为什么FPGA适合这个AI计算？"}
{"wav_id": "43", "speaker": "43", "offset": "1570.100", "duration": "10.040", "wav": "43.wav", "translation": "First, it has a large number of computing units, including DSPs, LUTs, registers, SRAMs, and high-bandwidth DDRs.", "transcript": "首先刚才也讲过，它有大量的这这种计算单元DSP、LUT、寄存器、SRAM、高带宽的DDR等等等等。"}
{"wav_id": "43", "speaker": "43", "offset": "1581.010", "duration": "3.150", "wav": "43.wav", "translation": "In addition, it uses the latest process technology.", "transcript": "而且它的工艺也是跟紧跟最新的工艺。"}
{"wav_id": "43", "speaker": "43", "offset": "1585.430", "duration": "2.870", "wav": "43.wav", "translation": "Second, its architecture is very innovative and develop in high speed.", "transcript": "然后它的架构创新非常地活跃、非常地快。"}
{"wav_id": "43", "speaker": "43", "offset": "1589.000", "duration": "4.280", "wav": "43.wav", "translation": "These advantages make FPGAs ideal for AI computing.", "transcript": "所有这些优势加在一起，所以让FPGA非常适合AI的计算。"}
{"wav_id": "43", "speaker": "43", "offset": "1594.330", "duration": "6.550", "wav": "43.wav", "translation": "Baidu noticed this technological trend five or six years ago and firmly seized related technological opportunities.", "transcript": "啊那百度就是在五六年前就已经看到这样一个技术趋势，并且牢牢地抓住这样一个技术的机会。"}
{"wav_id": "43", "speaker": "43", "offset": "1601.330", "duration": "2.580", "wav": "43.wav", "translation": "We have explored this field since then.", "transcript": "我们大概有五年多六年的这样一个探索。"}
{"wav_id": "43", "speaker": "43", "offset": "1605.360", "duration": "8.980", "wav": "43.wav", "translation": "We provide the best computational performance and the largest FPGA-AI cluster in the industry. We have paid a high price and made great efforts.", "transcript": "我们基本上是业界最大规模的FPGA-AI的一个集群，我们花了很大的代价、很多的努力，在这方面，同时能提供业界最优的计算效能。"}
{"wav_id": "43", "speaker": "43", "offset": "1614.780", "duration": "6.390", "wav": "43.wav", "translation": "Our work has received the highest recognition in the industry: three papers at Hot Chips.", "transcript": "而且我们所有这些工作都得到了业界一个最高的认可：Hotchips上三篇论文。"}
{"wav_id": "43", "speaker": "43", "offset": "1621.430", "duration": "2.870", "wav": "43.wav", "translation": "That's all for today.", "transcript": "今天的课程内容就为大家介绍到这些。"}
{"wav_id": "43", "speaker": "43", "offset": "1624.550", "duration": "7.470", "wav": "43.wav", "translation": "If you want to understand more, log in to ai.baidu.com and give us your real-time feedback.", "transcript": "如果大家要想要了解更多的内容，可以登录ai.baidu.com，实时反馈信息给我们。"}
{"wav_id": "43", "speaker": "43", "offset": "1632.250", "duration": "0.670", "wav": "43.wav", "translation": "Thank you!", "transcript": "谢谢大家！"}
